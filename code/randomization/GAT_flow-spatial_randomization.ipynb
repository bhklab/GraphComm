{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import liana as li\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "from openproblems import tasks\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1op-CbyLuN4",
    "outputId": "77aaf048-dc7e-491d-a0ed-7a13f3692cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n",
      "1.13.1+cu117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "# Helper function for visualization.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import Entities\n",
    "from torch_geometric.nn import FastRGCNConv, RGCNConv, GCNConv, InnerProductDecoder, GAE, VGAE\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data.data import Data\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing from original matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"/data/Sikander_data/Visium-FZ_GT_P19.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.DataFrame.sparse.from_spmatrix(adata.X,index=adata.obs.index.tolist(),columns=adata.var[\"feature_name\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame({\"cell\":adata.obs.index.tolist(),\"labels\":adata.obs[\"cell_type_original\"].tolist()})\n",
    "meta.index = meta[\"cell\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix[meta.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import anndata\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = matrix.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['labels'] = meta[\"labels\"].astype(\"string\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[\"cell\"] = meta[\"cell\"].astype(\"category\")\n",
    "meta[\"labels\"] = meta[\"labels\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix.loc[:,~matrix.columns.duplicated()].copy()\n",
    "meta = meta.loc[~meta.index.duplicated(),:].copy()\n",
    "cell_group = meta.groupby(\"labels\").count()\n",
    "valid_cell_groups = cell_group[cell_group[\"cell\"] > 1].index.tolist()\n",
    "meta = meta[meta[\"labels\"].isin(valid_cell_groups)]\n",
    "meta[\"labels\"] = meta[\"labels\"].cat.remove_unused_categories()\n",
    "matrix = matrix[meta[\"cell\"].tolist()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.AnnData(matrix.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(adata, min_cells=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata = anndata.AnnData(matrix.transpose())\n",
    "adata.obs[\"labels\"] =  meta[\"labels\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs = meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.tl.rank_genes_groups(adata, 'labels')\n",
    "cell_groups = meta['labels'].unique().tolist()\n",
    "matrix_list = {}\n",
    "for i in cell_groups:\n",
    "    cells = meta[meta[\"labels\"]==i].index.tolist()\n",
    "    temp_matrix = matrix[cells]\n",
    "    matrix_list[i] = (temp_matrix.mean(axis=1)[temp_matrix.mean(axis=1) > 0].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata.obs = meta\n",
    "# sc.tl.rank_genes_groups(adata, 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.tl.rank_genes_groups(adata, 'labels')\n",
    "\n",
    "\n",
    "# # In[12]:\n",
    "\n",
    "\n",
    "# pval_df = pd.DataFrame.from_records(adata.uns[\"rank_genes_groups\"][\"pvals\"])\n",
    "# pval_df.index = matrix.index.tolist()\n",
    "\n",
    "\n",
    "# # In[13]:\n",
    "\n",
    "\n",
    "# cell_type_df = {}\n",
    "# for i in pval_df.columns.tolist():\n",
    "#     sub = pval_df[i]\n",
    "#     sub = sub[sub < 0.05]\n",
    "#     cell_type_df[i] = sub.index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata = adata.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.obs[\"Gene\"] = matrix.index.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pval_df = pd.DataFrame.from_records(adata.uns[\"rank_genes_groups\"][\"pvals\"])\n",
    "# pval_df.index = adata.var.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_type_df = {}\n",
    "# for i in pval_df.columns.tolist():\n",
    "#     sub = pval_df[i]\n",
    "#     sub = sub[sub < 0.05]\n",
    "#     cell_type_df[i] = sub.index.tolist()\n",
    "cell_type_df = matrix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_expression = np.mean(matrix.values[matrix.values != 0])\n",
    "nodes = pd.DataFrame({\"category\":[],\"identifier\":[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes = pd.read_csv(\"../data/LR_database/OmniPath_nodes.csv\",index_col=0)\n",
    "Omnipath_network = pd.read_csv(\"../data/LR_database/OmniPath_interactions.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligands = LR_nodes[LR_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "receptors = LR_nodes[LR_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_list = []\n",
    "receptor_list = []\n",
    "new_cell_df = {}\n",
    "for i in cell_type_df.keys():\n",
    "    ligand_list.extend(list(set(ligands) & set(cell_type_df[i])))\n",
    "    receptor_list.extend(list(set(receptors) & set(cell_type_df[i])))\n",
    "    new_cell_df[i] = [list(set(ligands) & set(cell_type_df[i])),list(set(receptors) & set(cell_type_df[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_cell_df.keys():\n",
    "    new_cell_df[i][0] = [j+\"_Ligand\" for j in new_cell_df[i][0]]\n",
    "    new_cell_df[i][1] = [j+\"_Receptor\" for j in new_cell_df[i][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_list = list(set(ligand_list))\n",
    "receptor_list = list(set(receptor_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_list = [i+\"_Ligand\" for i in ligand_list]\n",
    "receptor_list = [i+\"_Receptor\" for i in receptor_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.concat([nodes,pd.DataFrame({\"category\":[\"Cell Group\"] * len(list(cell_type_df.keys())), \"identifier\":list(cell_type_df.keys())})])\n",
    "nodes = pd.concat([nodes,pd.DataFrame({\"category\":[\"Ligand\"] * len(ligand_list), \"identifier\":ligand_list})])\n",
    "nodes = pd.concat([nodes,pd.DataFrame({\"category\":[\"Receptor\"] * len(receptor_list), \"identifier\":receptor_list})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_identifier = [row[\"identifier\"] + \"_\" + row[\"category\"] for index,row in LR_nodes.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes[\"identifier\"] = new_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[\"Id\"] = range(0,nodes.shape[0])\n",
    "nodes = nodes[[\"Id\",\"category\",\"identifier\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.index = nodes.index.astype('int')\n",
    "nodes[\"Id\"] = nodes[\"Id\"].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.index = meta[\"cell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.DataFrame({\"Src\":[],\"Dst\":[],\"Weight\":[],\"edge_type\":[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes.index = LR_nodes[\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"identifier\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = []\n",
    "dest_list = []\n",
    "weight_list = []\n",
    "edge_type_list = []\n",
    "for i in new_cell_df.keys():\n",
    "    source_list.extend([i] * (len(new_cell_df[i][0]) + len(new_cell_df[i][1])))\n",
    "    dest_list.extend(new_cell_df[i][0])\n",
    "    dest_list.extend(new_cell_df[i][1])\n",
    "    weight_list.extend([1] * (len(new_cell_df[i][0]) + len(new_cell_df[i][1])))\n",
    "    edge_type_list.extend([1] * (len(new_cell_df[i][0]) + len(new_cell_df[i][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[\"Src\"] = source_list\n",
    "interactions[\"Dst\"] = dest_list\n",
    "interactions[\"Weight\"] = weight_list\n",
    "interactions[\"edge_type\"] = edge_type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.index = nodes[\"identifier\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nodes.drop_duplicates(\"identifier\")\n",
    "nodes[\"Id\"] = range(0,nodes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[\"Src\"] = nodes.loc[interactions[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "interactions[\"Dst\"] = nodes.loc[interactions[\"Dst\"].tolist()][\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data,first_nodes,first_interactions = make_dataset(nodes,interactions,first=False,pathway_encode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction with GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self,data,num_classes=3):\n",
    "        super(GAT, self).__init__()\n",
    "        self.hid = 3\n",
    "        self.in_head = 3\n",
    "        self.out_head = 3\n",
    "        \n",
    "        \n",
    "        self.conv1 = GATConv(data.x.shape[1], self.hid, heads=self.in_head, dropout=0.6)\n",
    "        self.conv2 = GATConv(self.hid*self.in_head,num_classes, concat=False,\n",
    "                             heads=self.out_head, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "                \n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.logsigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Omnipath embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes = pd.read_csv(\"../data/LR_database/OmniPath_nodes.csv\",index_col=0)\n",
    "Omnipath_network = pd.read_csv(\"../data/LR_database/OmniPath_interactions.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_identifier = [row[\"identifier\"] + \"_\" + row[\"category\"] for index,row in LR_nodes.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes[\"identifier\"] = new_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\\n            ...\\n             693, 1010,  178,   29, 3323,  268,  268,   43,  239,  239],\\n           dtype='int64', length=31729)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m LR_nodes\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m LR_nodes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 2\u001b[0m Omnipath_network[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSrc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mLR_nodes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mOmnipath_network\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSrc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m Omnipath_network[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDst\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m LR_nodes\u001b[38;5;241m.\u001b[39mloc[Omnipath_network[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDst\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:931\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    928\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    930\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 931\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1151\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:1093\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1093\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1095\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:1314\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1312\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 1314\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_read_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(ax\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1317\u001b[0m     ax, (IntervalIndex, CategoricalIndex)\n\u001b[1;32m   1318\u001b[0m ):\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# For CategoricalIndex take instead of reindex to preserve dtype.\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;66;03m#  For IntervalIndex this is to map integers to the Intervals they match to.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:1374\u001b[0m, in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   1373\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 1374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1376\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\\n            ...\\n             693, 1010,  178,   29, 3323,  268,  268,   43,  239,  239],\\n           dtype='int64', length=31729)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"identifier\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes = LR_nodes[(LR_nodes[\"identifier\"].isin(ligand_list)) | (LR_nodes[\"identifier\"].isin(receptor_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Omnipath_network = Omnipath_network[(Omnipath_network[\"Src\"].isin(LR_nodes[\"identifier\"].tolist())) & (Omnipath_network[\"Dst\"].isin(LR_nodes[\"identifier\"].tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes[\"Id\"] = range(0,LR_nodes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes.index = LR_nodes[\"identifier\"].tolist()\n",
    "Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes = LR_nodes[(LR_nodes[\"Id\"].isin(Omnipath_network[\"Src\"].tolist())) | (LR_nodes[\"Id\"].isin(Omnipath_network[\"Dst\"].tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes.index = LR_nodes[\"Id\"].tolist()\n",
    "Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"identifier\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes.index = LR_nodes[\"identifier\"].tolist()\n",
    "LR_nodes[\"Id\"] = range(0,LR_nodes.shape[0])\n",
    "Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Node2Vec\n",
    "import os.path as osp\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,loader,optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in (loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    z = model()\n",
    "    acc = model.test(z[data.train_mask], data.y[data.train_mask],\n",
    "                     z[data.test_mask], data.y[data.test_mask],\n",
    "                     max_iter=150)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Omnipath_embeddings(nodes,interactions):\n",
    "    Omnipath_data,Omnipath_nodes,Omnipath_interactions = make_dataset(nodes,interactions,first=False,pathway_encode=False)\n",
    "    node_info = pd.DataFrame(np.zeros((Omnipath_nodes.shape[0],Omnipath_nodes.shape[0])),index=Omnipath_nodes[\"identifier\"].tolist(),columns=Omnipath_nodes[\"identifier\"].tolist())\n",
    "\n",
    "    temp_identifiers = [i.split(\"_\")[0] for i in Omnipath_nodes[\"identifier\"].tolist()]\n",
    "\n",
    "    complexes = pd.read_csv(\"../data/data/LR_database/complexes.csv\")\n",
    "    complexes = complexes[complexes[\"member\"].isin(temp_identifiers)]\n",
    "\n",
    "    temp_nodes = Omnipath_nodes.copy()\n",
    "    temp_nodes.index = temp_identifiers\n",
    "    temp_nodes = temp_nodes[~temp_nodes.index.duplicated(keep='first')]\n",
    "\n",
    "    complexes[\"member\"] = temp_nodes.loc[complexes[\"member\"].tolist()][\"identifier\"].tolist()\n",
    "\n",
    "    group_complex = complexes.groupby(\"complex\").agg(list)\n",
    "\n",
    "    group_complex.index=range(0,group_complex.shape[0])\n",
    "\n",
    "    for index,row in group_complex.iterrows():\n",
    "        node_info.loc[list(set(row[\"member\"])),list(set(row[\"member\"]))] = index\n",
    "\n",
    "    # for i in group_complex[\"member\"].tolist():\n",
    "    #     node_info.loc[list(set(i)),list(set(i))] = 1\n",
    "\n",
    "    pathways = pd.read_csv(\"../data/kegg_pathways.csv\",index_col=0)\n",
    "    pathways = pathways[pathways[\"genesymbol\"].isin(temp_identifiers)]\n",
    "    pathways[\"genesymbol\"] = temp_nodes.loc[pathways[\"genesymbol\"].tolist()][\"identifier\"].tolist()\n",
    "    group_pathway = pathways.groupby(\"pathway\").agg(list)\n",
    "\n",
    "    group_pathway.index=range(0,group_pathway.shape[0])\n",
    "\n",
    "    for index,row in group_pathway.iterrows():\n",
    "        node_info.loc[list(set(row[\"genesymbol\"])),list(set(row[\"genesymbol\"]))] += index\n",
    "\n",
    "    # for i in group_pathway[\"genesymbol\"].tolist():\n",
    "    #     node_info.loc[list(set(i)),list(set(i))] += 1\n",
    "\n",
    "    truth_info = pd.DataFrame(np.zeros((Omnipath_nodes.shape[0],Omnipath_nodes.shape[0])),index=Omnipath_nodes[\"identifier\"].tolist(),columns=Omnipath_nodes[\"identifier\"].tolist())\n",
    "\n",
    "    Omnipath_nodes.index = Omnipath_nodes[\"Id\"].tolist()\n",
    "\n",
    "    ident_interactions = Omnipath_interactions.copy()\n",
    "    ident_interactions[\"Src\"] = Omnipath_nodes.loc[ident_interactions[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "    ident_interactions[\"Dst\"] = Omnipath_nodes.loc[ident_interactions[\"Dst\"].tolist()][\"identifier\"].tolist()\n",
    "\n",
    "    for index,row in ident_interactions.iterrows():\n",
    "        truth_info.loc[row[\"Src\"],row[\"Dst\"]] = 1\n",
    "\n",
    "    ligands = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "    receptors = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()\n",
    "    #truth_info = truth_info.loc[ligands,receptors]\n",
    "    truth_info = torch.Tensor(truth_info.values).to(device)\n",
    "\n",
    "\n",
    "    ligands = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "    receptors = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "\n",
    "    ident_interactions = ident_interactions.drop_duplicates(\"Src\")\n",
    "    ident_interactions = ident_interactions.drop_duplicates(\"Dst\")\n",
    "\n",
    "    ident_interactions.index = range(0,ident_interactions.shape[0])\n",
    "\n",
    "    truth_list = []\n",
    "    for i in Omnipath_nodes[\"identifier\"].tolist():\n",
    "        if \"Ligand\" in i:\n",
    "            if i in ident_interactions[\"Src\"].tolist():\n",
    "                #truth_list.append(ident_interactions[ident_interactions[\"Src\"]==i].index.tolist()[0] + 1)\n",
    "                truth_list.append(1)\n",
    "            else:\n",
    "                truth_list.append(0)\n",
    "        if \"Receptor\" in i:\n",
    "            if i in ident_interactions[\"Dst\"].tolist():\n",
    "                #truth_list.append(ident_interactions[ident_interactions[\"Dst\"]==i].index.tolist()[0] + 1)\n",
    "                truth_list.append(1)\n",
    "            else:\n",
    "                truth_list.append(0)\n",
    "\n",
    "    node_info.values[np.where(np.isnan(node_info.values))] = 0\n",
    "    node_info.values[np.where(np.isinf(node_info.values))] = 0\n",
    "\n",
    "    Omnipath_data.x = torch.Tensor(node_info.values)\n",
    "\n",
    "    Omnipath_data.y = torch.Tensor(truth_list).type(torch.LongTensor)\n",
    "    #Omnipath_data.y = truth_info\n",
    "\n",
    "    Omnipath_nodes.index = Omnipath_nodes[\"Id\"].tolist()\n",
    "\n",
    "    Omnipath_interactions[\"Src\"] = [Omnipath_nodes.loc[i][\"identifier\"] for i in Omnipath_interactions[\"Src\"].tolist()]\n",
    "    Omnipath_interactions[\"Dst\"] = [Omnipath_nodes.loc[i][\"identifier\"] for i in Omnipath_interactions[\"Dst\"].tolist()]\n",
    "\n",
    "    #edge_weights = [max(node_info.loc[i,j],node_info.loc[j,i]) for i,j in zip(Omnipath_interactions[\"Src\"].tolist(),Omnipath_interactions[\"Dst\"].tolist())]\n",
    "    edge_weights = [1 for i,j in zip(Omnipath_interactions[\"Src\"].tolist(),Omnipath_interactions[\"Dst\"].tolist())]\n",
    "    data = Omnipath_data\n",
    "    model = Node2Vec(data.edge_index, embedding_dim=2, walk_length=40,\n",
    "         context_size=40, walks_per_node=10,\n",
    "         num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
    "\n",
    "    loader = model.loader(batch_size=2, shuffle=True, num_workers=4)\n",
    "    optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
    "    \n",
    "    \n",
    "    for epoch in range(1):\n",
    "        loss = train(model,loader,optimizer)\n",
    "        #acc = test()\n",
    "#         if epoch % 10 == 0:\n",
    "#             print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "    model.eval()\n",
    "    z = model(torch.arange(data.num_nodes)).detach()\n",
    "\n",
    "    ligand_ids = Omnipath_nodes[Omnipath_nodes[\"category\"].str.contains(\"Ligand\")][\"Id\"].tolist()\n",
    "    receptor_ids = Omnipath_nodes[Omnipath_nodes[\"category\"].str.contains(\"Receptor\")][\"Id\"].tolist()\n",
    "\n",
    "    ligand_embeddings = z[ligand_ids,:]\n",
    "    receptor_embeddings = z[receptor_ids,:]\n",
    "\n",
    "    total_embeddings = torch.inner(ligand_embeddings,receptor_embeddings)\n",
    "\n",
    "    total_embeddings_df = pd.DataFrame(total_embeddings.numpy(),index=Omnipath_nodes[Omnipath_nodes[\"category\"].str.contains(\"Ligand\")][\"identifier\"].tolist(),columns=Omnipath_nodes[Omnipath_nodes[\"category\"].str.contains(\"Receptor\")][\"identifier\"].tolist())\n",
    "    return total_embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if (Omnipath_network[\"Src\"].dtype != 'float64') and (Omnipath_network[\"Src\"].dtype != 'int64'):\n",
    "        LR_nodes.index = LR_nodes[\"identifier\"].tolist()\n",
    "        LR_nodes[\"Id\"] = range(0,LR_nodes.shape[0])\n",
    "        Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "        Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"Id\"].tolist()\n",
    "Omnipath_data,Omnipath_nodes,Omnipath_interactions = make_dataset(LR_nodes,Omnipath_network,first=False,pathway_encode=False)\n",
    "Omnipath_nodes.index = Omnipath_nodes[\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "def get_cell_LR_embeddings(nodes,interactions,total_embeddings_df,Omnipath_nodes):\n",
    "    device = 'cpu'\n",
    "    truth_info = pd.DataFrame(np.zeros((Omnipath_nodes.shape[0],Omnipath_nodes.shape[0])),index=Omnipath_nodes[\"identifier\"].tolist(),columns=Omnipath_nodes[\"identifier\"].tolist())\n",
    "\n",
    "    #Omnipath_nodes.index = Omnipath_nodes[\"Id\"].tolist()\n",
    "\n",
    "    ident_interactions = Omnipath_interactions.copy()\n",
    "    ident_interactions[\"Src\"] = Omnipath_nodes.loc[ident_interactions[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "    ident_interactions[\"Dst\"] = Omnipath_nodes.loc[ident_interactions[\"Dst\"].tolist()][\"identifier\"].tolist()\n",
    "\n",
    "    for index,row in ident_interactions.iterrows():\n",
    "        truth_info.loc[row[\"Src\"],row[\"Dst\"]] = 1\n",
    "\n",
    "    ligands = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "    receptors = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()\n",
    "    #truth_info = truth_info.loc[ligands,receptors]\n",
    "    truth_info = torch.Tensor(truth_info.values).to(device)\n",
    "\n",
    "    \n",
    "    cell_LR_data,cell_LR_nodes,cell_LR_ints = make_dataset(nodes,interactions,first=False,pathway_encode=False)\n",
    "\n",
    "    full_matrix = pd.DataFrame(np.zeros((cell_LR_nodes.shape[0],cell_LR_nodes.shape[0])),index=cell_LR_nodes[\"identifier\"].tolist(),columns=cell_LR_nodes[\"identifier\"].tolist())\n",
    "\n",
    "    ligands = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "    receptors = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "    total_out_df = total_embeddings_df\n",
    "\n",
    "    gene_mean = matrix.mean(axis=1)\n",
    "\n",
    "    Omnipath_nodes.index = [i.split(\"_\")[0] for i in Omnipath_nodes[\"identifier\"].tolist()]\n",
    "\n",
    "    Omnipath_nodes = Omnipath_nodes.loc[~Omnipath_nodes.index.duplicated(),:].copy()\n",
    "    \n",
    "\n",
    "    gene_mean = gene_mean.loc[Omnipath_nodes.index.tolist()]\n",
    "\n",
    "    gene_mean.index = Omnipath_nodes[\"identifier\"].tolist()\n",
    "\n",
    "    ligands = [i for i in gene_mean.index.tolist() if \"Ligand\" in i]\n",
    "    receptors = [i for i in gene_mean.index.tolist() if \"Receptor\" in i]\n",
    "    ligands = list(set(full_matrix.index.tolist()) & set(ligands))\n",
    "    receptors = list(set(full_matrix.index.tolist()) & set(receptors))\n",
    "\n",
    "    for i,j in zip(ligands,receptors):\n",
    "        if (i in gene_mean.index.tolist()) and (j in gene_mean.index.tolist()):\n",
    "            full_matrix.loc[i,j] = gene_mean.loc[i]*gene_mean.loc[j]\n",
    "\n",
    "    ligands = list(set(ligands) & set(total_out_df.index.tolist()))\n",
    "    receptors = list(set(receptors) & set(total_out_df.columns.tolist()))\n",
    "\n",
    "    for i,j in zip(ligands,receptors):\n",
    "        full_matrix.loc[i,j] += total_out_df.loc[i,j]\n",
    "\n",
    "\n",
    "    #full_matrix.loc[true_df.index.tolist(),true_df.columns.tolist()] = true_df.values\n",
    "\n",
    "    cell_groups = meta[\"labels\"].unique().tolist()\n",
    "\n",
    "    ligands = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "    ligands = [i.split(\"_\")[0] for i in ligands]\n",
    "    ligand_matrix = matrix.loc[ligands]\n",
    "\n",
    "    ligand_matrix = ligand_matrix[~ligand_matrix.index.duplicated(keep='first')]\n",
    "\n",
    "\n",
    "    mean_dict = {}\n",
    "    for i in cell_groups:\n",
    "        cells = meta[meta[\"labels\"]==i][\"cell\"].tolist()\n",
    "        mean_dict[i] = ligand_matrix[cells].mean(axis=1)\n",
    "\n",
    "    full_matrix = full_matrix[~full_matrix.index.duplicated(keep='first')]\n",
    "    full_matrix = full_matrix.loc[:,~full_matrix.columns.duplicated()].copy()\n",
    "\n",
    "\n",
    "    for i in mean_dict.keys():\n",
    "        temp_index = [i+\"_Ligand\" for i in mean_dict[i].index.tolist()]\n",
    "        full_matrix.loc[i,temp_index] = mean_dict[i].values\n",
    "        full_matrix.loc[temp_index,i] = mean_dict[i].values\n",
    "\n",
    "    receptors = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()\n",
    "    receptors = [i.split(\"_\")[0] for i in receptors]\n",
    "    receptors_matrix = matrix.loc[receptors]\n",
    "\n",
    "    receptors_matrix = receptors_matrix[~receptors_matrix.index.duplicated(keep='first')]\n",
    "\n",
    "\n",
    "    mean_dict = {}\n",
    "    for i in cell_groups:\n",
    "        cells = meta[meta[\"labels\"]==i][\"cell\"].tolist()\n",
    "        mean_dict[i] = receptors_matrix[cells].mean(axis=1)\n",
    "\n",
    "    full_matrix = full_matrix[~full_matrix.index.duplicated(keep='first')]\n",
    "    full_matrix = full_matrix.loc[:,~full_matrix.columns.duplicated()].copy()\n",
    "\n",
    "\n",
    "    for i in mean_dict.keys():\n",
    "        temp_index = [i+\"_Receptor\" for i in mean_dict[i].index.tolist()]\n",
    "        full_matrix.loc[i,temp_index] = mean_dict[i].values\n",
    "        full_matrix.loc[temp_index,i] = mean_dict[i].values\n",
    "\n",
    "    #full_matrix = (full_matrix - np.min(full_matrix)) / (np.max(full_matrix) - np.min(full_matrix))\n",
    "\n",
    "    full_matrix.values[np.where(np.isnan(full_matrix.values))] = 0\n",
    "    full_matrix.values[np.where(np.isinf(full_matrix.values))] = 0\n",
    "\n",
    "    adata = sc.read_h5ad(\"../data/Sikander_data/Visium-FZ_GT_P19.h5ad\")\n",
    "    adata = adata[meta.index.tolist()]\n",
    "\n",
    "    spatial_coordinates = adata.obsm[\"X_spatial\"]\n",
    "\n",
    "    spatial_df = pd.DataFrame({\"x\":spatial_coordinates[:,0],\"y\":spatial_coordinates[:,1]},index=meta.index.tolist())\n",
    "\n",
    "    cell_groups = meta[\"labels\"].unique().tolist()\n",
    "\n",
    "    import math\n",
    "\n",
    "    spatial_dict = {}\n",
    "    for i in cell_groups:\n",
    "        cells = meta[meta[\"labels\"]==i].index.tolist()\n",
    "        spatial_coords = [(i,j) for i,j in zip(spatial_df.loc[cells][\"x\"].tolist(),spatial_df.loc[cells][\"y\"].tolist())]\n",
    "        for j in cell_groups:\n",
    "            if j != i:\n",
    "                second_cells = meta[meta[\"labels\"]==j].index.tolist()\n",
    "                second_spatial_coords = [(i,j) for i,j in zip(spatial_df.loc[second_cells][\"x\"].tolist(),spatial_df.loc[second_cells][\"y\"].tolist())]\n",
    "                min_list = []\n",
    "                for k in spatial_coords:\n",
    "                    min_list.append(min([math.dist(k,l) for l in second_spatial_coords]))\n",
    "                spatial_dict[(i,j)] = min(min_list)\n",
    "\n",
    "\n",
    "    for k in spatial_dict.keys():\n",
    "        full_matrix.loc[k[0],k[1]] = spatial_dict[k]\n",
    "        full_matrix.loc[k[1],k[0]] = spatial_dict[k]\n",
    "\n",
    "    cell_LR_data.x = torch.Tensor(full_matrix.values)\n",
    "\n",
    "    LR_ids = cell_LR_nodes[(cell_LR_nodes[\"category\"]==\"Ligand\") | (cell_LR_nodes[\"category\"]==\"Receptor\")][\"Id\"].tolist()\n",
    "\n",
    "    # true_values[\"Src\"] = [i + \"_Ligand\" for i in true_values[\"Src\"].tolist()]\n",
    "    # true_values[\"Dst\"] = [i + \"_Receptor\" for i in true_values[\"Dst\"].tolist()]\n",
    "\n",
    "    cell_groups = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Cell Group\"]['identifier'].tolist()\n",
    "\n",
    "    truth_list = []\n",
    "    for i in cell_LR_nodes[\"identifier\"].tolist():\n",
    "        if \"Ligand\" in i:\n",
    "            if i in ident_interactions[\"Src\"].tolist():\n",
    "                #truth_list.append(ident_interactions[ident_interactions[\"Src\"]==i].index.tolist()[0] + 1)\n",
    "                truth_list.append(1)\n",
    "            else:\n",
    "                truth_list.append(0)\n",
    "        elif \"Receptor\" in i:\n",
    "            if i in ident_interactions[\"Dst\"].tolist():\n",
    "                #truth_list.append(ident_interactions[ident_interactions[\"Dst\"]==i].index.tolist()[0] + 1)\n",
    "                truth_list.append(1)\n",
    "            else:\n",
    "                truth_list.append(0)\n",
    "        else:\n",
    "            truth_list.append(2)\n",
    "\n",
    "    cell_LR_data.y = torch.Tensor(truth_list).type(torch.LongTensor)\n",
    "\n",
    "    truth_array = np.array(truth_list)\n",
    "    positive_classes = np.where(truth_array==1)[0].tolist()\n",
    "    negative_classes = np.where(truth_array==0)[0].tolist()[:len(positive_classes)]\n",
    "\n",
    "    new_train_mask = np.array([False]*truth_array.shape[0])\n",
    "    new_train_mask[positive_classes + negative_classes] = True\n",
    "\n",
    "    model = GAT(cell_LR_data,num_classes=2).to(device)\n",
    "    data = cell_LR_data.to(device)\n",
    "    data.train_mask = torch.Tensor(new_train_mask).type(torch.LongTensor)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    ligands = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "    receptors = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "    truth_df = full_matrix.loc[cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist(),cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()]\n",
    "\n",
    "    truth_Tensor = torch.Tensor(truth_df.values).to(device)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        #loss = F.nll_loss(out[new_train_mask],data.y[new_train_mask])\n",
    "        ligand_out = out[ligands,:]\n",
    "        receptor_out = out[receptors,:]\n",
    "        total_out = torch.inner(ligand_out,receptor_out)\n",
    "        #loss = criterion(out[LR_ids],data.y)\n",
    "        #loss = criterion(total_out,truth_Tensor)\n",
    "        loss = criterion(out[new_train_mask],data.y[new_train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    cell_LR_out = model(data)\n",
    "\n",
    "    ligands = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "    receptors = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "    ligand_out = cell_LR_out[ligands,:]\n",
    "    receptor_out = cell_LR_out[receptors,:]\n",
    "    _,ligand_pred = ligand_out.max(dim=1)\n",
    "    _,receptor_pred = receptor_out.max(dim=1)\n",
    "\n",
    "    total_out = torch.inner(ligand_out,receptor_out).cpu().detach().numpy()\n",
    "    ligand_pred = ligand_pred.cpu().detach().numpy()\n",
    "    receptor_pred = receptor_pred.cpu().detach().numpy()\n",
    "    \n",
    "    cell_LR_nodes.index = cell_LR_nodes[\"Id\"].tolist()\n",
    "    valid_ligands = cell_LR_nodes.loc[np.where(ligand_pred == 1)]\n",
    "    valid_receptors = cell_LR_nodes.loc[np.where(receptor_pred == 1)]\n",
    "    ligand_out = ligand_out[np.where(ligand_pred ==1)]\n",
    "    receptor_out = receptor_out[np.where(receptor_pred ==1)]  \n",
    "    total_out = torch.inner(ligand_out,receptor_out).cpu().detach().numpy()\n",
    "    ligand_nodes = cell_LR_nodes[cell_LR_nodes[\"category\"] == \"Ligand\"]\n",
    "    ligand_nodes.index = range(0,ligand_nodes.shape[0])\n",
    "    ligand_idents = ligand_nodes.iloc[np.where(ligand_pred==1)]['identifier'].tolist()\n",
    "    total_out_df = pd.DataFrame(total_out,index=valid_ligands[\"identifier\"].tolist(),columns=valid_receptors[\"identifier\"].tolist())\n",
    "    indicies = np.where(total_out_df.values > 0)\n",
    "    source = list(indicies[0])\n",
    "    dest = list(indicies[1])\n",
    "    index_df = pd.DataFrame({\"Id\":range(0,total_out_df.shape[0]),\"identifier\":total_out_df.index.tolist()})\n",
    "    column_df = pd.DataFrame({\"Id\":range(0,total_out_df.shape[1]),\"identifier\":total_out_df.columns.tolist()})\n",
    "    source_list = index_df.loc[source][\"identifier\"].tolist()\n",
    "    dest_list = column_df.loc[dest][\"identifier\"].tolist()\n",
    "    total_link_df = pd.DataFrame({\"Src\":source_list,\"Dst\":dest_list,\"Prob\":total_out_df.values[indicies]})\n",
    "    total_link_df = total_link_df.sort_values(\"Prob\",ascending=False)\n",
    "    Omnipath_db = pd.read_csv(\"../data/LR_database/Omnipath_database.csv\")\n",
    "    total_link_df[\"Src\"] = [i.split(\"_\")[0] for i in total_link_df[\"Src\"].tolist()]\n",
    "    total_link_df[\"Dst\"] = [i.split(\"_\")[0] for i in total_link_df[\"Dst\"].tolist()]\n",
    "    total_link_df = total_link_df.drop_duplicates()\n",
    "    return total_link_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Done Preprocessing\n",
      "Done Omnipath embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    Omnipath_network[\"Src\"] = Omnipath_network[\"Src\"].sample(frac=1).tolist()\n",
    "    Omnipath_network[\"Dst\"] = Omnipath_network[\"Dst\"].sample(frac=1).tolist()\n",
    "    if (Omnipath_network[\"Src\"].dtype != 'float64') and (Omnipath_network[\"Src\"].dtype != 'int64'):\n",
    "        LR_nodes.index = LR_nodes[\"identifier\"].tolist()\n",
    "        LR_nodes[\"Id\"] = range(0,LR_nodes.shape[0])\n",
    "        Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "        Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"Id\"].tolist()\n",
    "    print(\"Done Preprocessing\")\n",
    "    df = get_Omnipath_embeddings(LR_nodes,Omnipath_network)\n",
    "    print(\"Done Omnipath embeddings\")\n",
    "    interactions[\"Src\"] = interactions[\"Src\"].sample(frac=1).tolist()\n",
    "    interactions[\"Dst\"] = interactions[\"Dst\"].sample(frac=1).tolist()  \n",
    "    Omnipath_nodes.index = Omnipath_nodes[\"identifier\"].tolist()\n",
    "    df_list.append(get_cell_LR_embeddings(nodes,interactions,df,Omnipath_nodes))\n",
    "    print(\"Done cell embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Preprocessing\n"
     ]
    }
   ],
   "source": [
    "Omnipath_network[\"Src\"] = Omnipath_network[\"Src\"].sample(frac=1).tolist()\n",
    "Omnipath_network[\"Dst\"] = Omnipath_network[\"Dst\"].sample(frac=1).tolist()\n",
    "if (Omnipath_network[\"Src\"].dtype != 'float64') and (Omnipath_network[\"Src\"].dtype != 'int64'):\n",
    "    LR_nodes.index = LR_nodes[\"identifier\"].tolist()\n",
    "    LR_nodes[\"Id\"] = range(0,LR_nodes.shape[0])\n",
    "    Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "    Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"Id\"].tolist()\n",
    "print(\"Done Preprocessing\")\n",
    "df = get_Omnipath_embeddings(LR_nodes,Omnipath_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "    interactions[\"Src\"] = interactions[\"Src\"].sample(frac=1).tolist()\n",
    "    interactions[\"Dst\"] = interactions[\"Dst\"].sample(frac=1).tolist()  \n",
    "    Omnipath_nodes.index = Omnipath_nodes[\"identifier\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_embeddings_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>category</th>\n",
       "      <th>identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NRP2_Ligand</th>\n",
       "      <td>0</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>NRP2_Ligand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NGFR_Ligand</th>\n",
       "      <td>1</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>NGFR_Ligand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENG_Ligand</th>\n",
       "      <td>2</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>ENG_Ligand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RYK_Ligand</th>\n",
       "      <td>3</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>RYK_Ligand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAS1_Ligand</th>\n",
       "      <td>4</td>\n",
       "      <td>Ligand</td>\n",
       "      <td>GAS1_Ligand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPP2R1B_Receptor</th>\n",
       "      <td>6395</td>\n",
       "      <td>Receptor</td>\n",
       "      <td>PPP2R1B_Receptor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMO4_Receptor</th>\n",
       "      <td>6396</td>\n",
       "      <td>Receptor</td>\n",
       "      <td>LMO4_Receptor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEY1_Receptor</th>\n",
       "      <td>6397</td>\n",
       "      <td>Receptor</td>\n",
       "      <td>HEY1_Receptor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZNF107_Receptor</th>\n",
       "      <td>6398</td>\n",
       "      <td>Receptor</td>\n",
       "      <td>ZNF107_Receptor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UXS1_Receptor</th>\n",
       "      <td>6399</td>\n",
       "      <td>Receptor</td>\n",
       "      <td>UXS1_Receptor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id  category        identifier\n",
       "NRP2_Ligand          0    Ligand       NRP2_Ligand\n",
       "NGFR_Ligand          1    Ligand       NGFR_Ligand\n",
       "ENG_Ligand           2    Ligand        ENG_Ligand\n",
       "RYK_Ligand           3    Ligand        RYK_Ligand\n",
       "GAS1_Ligand          4    Ligand       GAS1_Ligand\n",
       "...                ...       ...               ...\n",
       "PPP2R1B_Receptor  6395  Receptor  PPP2R1B_Receptor\n",
       "LMO4_Receptor     6396  Receptor     LMO4_Receptor\n",
       "HEY1_Receptor     6397  Receptor     HEY1_Receptor\n",
       "ZNF107_Receptor   6398  Receptor   ZNF107_Receptor\n",
       "UXS1_Receptor     6399  Receptor     UXS1_Receptor\n",
       "\n",
       "[6400 rows x 3 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Omnipath_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Dst</th>\n",
       "      <th>Weight</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SH3GLB1_Ligand</td>\n",
       "      <td>PTH1R_Receptor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FGR_Ligand</td>\n",
       "      <td>WIPF1_Receptor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HLA-C_Ligand</td>\n",
       "      <td>PPP4C_Receptor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IL1RAP_Ligand</td>\n",
       "      <td>PDPN_Receptor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KDM6A_Ligand</td>\n",
       "      <td>LILRA6_Receptor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40461</th>\n",
       "      <td>KLF6_Ligand</td>\n",
       "      <td>FGR_Receptor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40463</th>\n",
       "      <td>CYLD_Ligand</td>\n",
       "      <td>PTGER2_Receptor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40464</th>\n",
       "      <td>EHMT2_Ligand</td>\n",
       "      <td>MAP2K4_Receptor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40465</th>\n",
       "      <td>RARRES1_Ligand</td>\n",
       "      <td>MUC1_Receptor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40466</th>\n",
       "      <td>FBXW7_Ligand</td>\n",
       "      <td>PLSCR1_Receptor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25296 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Src              Dst  Weight  edge_type\n",
       "0      SH3GLB1_Ligand   PTH1R_Receptor       1          0\n",
       "1          FGR_Ligand   WIPF1_Receptor       1          0\n",
       "2        HLA-C_Ligand   PPP4C_Receptor       1          0\n",
       "3       IL1RAP_Ligand    PDPN_Receptor       1          0\n",
       "4        KDM6A_Ligand  LILRA6_Receptor       1          0\n",
       "...               ...              ...     ...        ...\n",
       "40461     KLF6_Ligand     FGR_Receptor       1          0\n",
       "40463     CYLD_Ligand  PTGER2_Receptor       1          0\n",
       "40464    EHMT2_Ligand  MAP2K4_Receptor       1          0\n",
       "40465  RARRES1_Ligand    MUC1_Receptor       1          0\n",
       "40466    FBXW7_Ligand  PLSCR1_Receptor       1          0\n",
       "\n",
       "[25296 rows x 4 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ident_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "truth_info = pd.DataFrame(np.zeros((Omnipath_nodes.shape[0],Omnipath_nodes.shape[0])),index=Omnipath_nodes[\"identifier\"].tolist(),columns=Omnipath_nodes[\"identifier\"].tolist())\n",
    "\n",
    "#Omnipath_nodes.index = Omnipath_nodes[\"Id\"].tolist()\n",
    "\n",
    "ident_interactions = Omnipath_interactions.copy()\n",
    "ident_interactions[\"Src\"] = Omnipath_nodes.loc[ident_interactions[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "ident_interactions[\"Dst\"] = Omnipath_nodes.loc[ident_interactions[\"Dst\"].tolist()][\"identifier\"].tolist()\n",
    "\n",
    "for index,row in ident_interactions.iterrows():\n",
    "    truth_info.loc[row[\"Src\"],row[\"Dst\"]] = 1\n",
    "\n",
    "ligands = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "receptors = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()\n",
    "#truth_info = truth_info.loc[ligands,receptors]\n",
    "truth_info = torch.Tensor(truth_info.values).to(device)\n",
    "\n",
    "\n",
    "cell_LR_data,cell_LR_nodes,cell_LR_ints = make_dataset(nodes,interactions,first=False,pathway_encode=False)\n",
    "\n",
    "full_matrix = pd.DataFrame(np.zeros((cell_LR_nodes.shape[0],cell_LR_nodes.shape[0])),index=cell_LR_nodes[\"identifier\"].tolist(),columns=cell_LR_nodes[\"identifier\"].tolist())\n",
    "\n",
    "ligands = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "receptors = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "total_out_df = total_embeddings_df\n",
    "\n",
    "gene_mean = matrix.mean(axis=1)\n",
    "\n",
    "Omnipath_nodes.index = [i.split(\"_\")[0] for i in Omnipath_nodes[\"identifier\"].tolist()]\n",
    "\n",
    "Omnipath_nodes = Omnipath_nodes.loc[~Omnipath_nodes.index.duplicated(),:].copy()\n",
    "\n",
    "\n",
    "gene_mean = gene_mean.loc[Omnipath_nodes.index.tolist()]\n",
    "\n",
    "gene_mean.index = Omnipath_nodes[\"identifier\"].tolist()\n",
    "\n",
    "ligands = [i for i in gene_mean.index.tolist() if \"Ligand\" in i]\n",
    "receptors = [i for i in gene_mean.index.tolist() if \"Receptor\" in i]\n",
    "ligands = list(set(full_matrix.index.tolist()) & set(ligands))\n",
    "receptors = list(set(full_matrix.index.tolist()) & set(receptors))\n",
    "\n",
    "for i,j in zip(ligands,receptors):\n",
    "    if (i in gene_mean.index.tolist()) and (j in gene_mean.index.tolist()):\n",
    "        full_matrix.loc[i,j] = gene_mean.loc[i]*gene_mean.loc[j]\n",
    "\n",
    "ligands = list(set(ligands) & set(total_out_df.index.tolist()))\n",
    "receptors = list(set(receptors) & set(total_out_df.columns.tolist()))\n",
    "\n",
    "for i,j in zip(ligands,receptors):\n",
    "    full_matrix.loc[i,j] += total_out_df.loc[i,j]\n",
    "\n",
    "\n",
    "#full_matrix.loc[true_df.index.tolist(),true_df.columns.tolist()] = true_df.values\n",
    "\n",
    "cell_groups = meta[\"labels\"].unique().tolist()\n",
    "\n",
    "ligands = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "ligands = [i.split(\"_\")[0] for i in ligands]\n",
    "ligand_matrix = matrix.loc[ligands]\n",
    "\n",
    "ligand_matrix = ligand_matrix[~ligand_matrix.index.duplicated(keep='first')]\n",
    "\n",
    "\n",
    "mean_dict = {}\n",
    "for i in cell_groups:\n",
    "    cells = meta[meta[\"labels\"]==i][\"cell\"].tolist()\n",
    "    mean_dict[i] = ligand_matrix[cells].mean(axis=1)\n",
    "\n",
    "full_matrix = full_matrix[~full_matrix.index.duplicated(keep='first')]\n",
    "full_matrix = full_matrix.loc[:,~full_matrix.columns.duplicated()].copy()\n",
    "\n",
    "\n",
    "for i in mean_dict.keys():\n",
    "    temp_index = [i+\"_Ligand\" for i in mean_dict[i].index.tolist()]\n",
    "    full_matrix.loc[i,temp_index] = mean_dict[i].values\n",
    "    full_matrix.loc[temp_index,i] = mean_dict[i].values\n",
    "\n",
    "receptors = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()\n",
    "receptors = [i.split(\"_\")[0] for i in receptors]\n",
    "receptors_matrix = matrix.loc[receptors]\n",
    "\n",
    "receptors_matrix = receptors_matrix[~receptors_matrix.index.duplicated(keep='first')]\n",
    "\n",
    "\n",
    "mean_dict = {}\n",
    "for i in cell_groups:\n",
    "    cells = meta[meta[\"labels\"]==i][\"cell\"].tolist()\n",
    "    mean_dict[i] = receptors_matrix[cells].mean(axis=1)\n",
    "\n",
    "full_matrix = full_matrix[~full_matrix.index.duplicated(keep='first')]\n",
    "full_matrix = full_matrix.loc[:,~full_matrix.columns.duplicated()].copy()\n",
    "\n",
    "\n",
    "for i in mean_dict.keys():\n",
    "    temp_index = [i+\"_Receptor\" for i in mean_dict[i].index.tolist()]\n",
    "    full_matrix.loc[i,temp_index] = mean_dict[i].values\n",
    "    full_matrix.loc[temp_index,i] = mean_dict[i].values\n",
    "\n",
    "#full_matrix = (full_matrix - np.min(full_matrix)) / (np.max(full_matrix) - np.min(full_matrix))\n",
    "\n",
    "full_matrix.values[np.where(np.isnan(full_matrix.values))] = 0\n",
    "full_matrix.values[np.where(np.isinf(full_matrix.values))] = 0\n",
    "\n",
    "adata = sc.read_h5ad(\"../data/Sikander_data/Visium-FZ_GT_P19.h5ad\")\n",
    "adata = adata[meta.index.tolist()]\n",
    "\n",
    "spatial_coordinates = adata.obsm[\"X_spatial\"]\n",
    "\n",
    "spatial_df = pd.DataFrame({\"x\":spatial_coordinates[:,0],\"y\":spatial_coordinates[:,1]},index=meta.index.tolist())\n",
    "\n",
    "cell_groups = meta[\"labels\"].unique().tolist()\n",
    "\n",
    "import math\n",
    "\n",
    "spatial_dict = {}\n",
    "for i in cell_groups:\n",
    "    cells = meta[meta[\"labels\"]==i].index.tolist()\n",
    "    spatial_coords = [(i,j) for i,j in zip(spatial_df.loc[cells][\"x\"].tolist(),spatial_df.loc[cells][\"y\"].tolist())]\n",
    "    for j in cell_groups:\n",
    "        if j != i:\n",
    "            second_cells = meta[meta[\"labels\"]==j].index.tolist()\n",
    "            second_spatial_coords = [(i,j) for i,j in zip(spatial_df.loc[second_cells][\"x\"].tolist(),spatial_df.loc[second_cells][\"y\"].tolist())]\n",
    "            min_list = []\n",
    "            for k in spatial_coords:\n",
    "                min_list.append(min([math.dist(k,l) for l in second_spatial_coords]))\n",
    "            spatial_dict[(i,j)] = min(min_list)\n",
    "\n",
    "\n",
    "for k in spatial_dict.keys():\n",
    "    full_matrix.loc[k[0],k[1]] = spatial_dict[k]\n",
    "    full_matrix.loc[k[1],k[0]] = spatial_dict[k]\n",
    "\n",
    "cell_LR_data.x = torch.Tensor(full_matrix.values)\n",
    "\n",
    "LR_ids = cell_LR_nodes[(cell_LR_nodes[\"category\"]==\"Ligand\") | (cell_LR_nodes[\"category\"]==\"Receptor\")][\"Id\"].tolist()\n",
    "\n",
    "# true_values[\"Src\"] = [i + \"_Ligand\" for i in true_values[\"Src\"].tolist()]\n",
    "# true_values[\"Dst\"] = [i + \"_Receptor\" for i in true_values[\"Dst\"].tolist()]\n",
    "\n",
    "cell_groups = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Cell Group\"]['identifier'].tolist()\n",
    "\n",
    "truth_list = []\n",
    "for i in cell_LR_nodes[\"identifier\"].tolist():\n",
    "    if \"Ligand\" in i:\n",
    "        if i in ident_interactions[\"Src\"].tolist():\n",
    "            #truth_list.append(ident_interactions[ident_interactions[\"Src\"]==i].index.tolist()[0] + 1)\n",
    "            truth_list.append(1)\n",
    "        else:\n",
    "            truth_list.append(0)\n",
    "    elif \"Receptor\" in i:\n",
    "        if i in ident_interactions[\"Dst\"].tolist():\n",
    "            #truth_list.append(ident_interactions[ident_interactions[\"Dst\"]==i].index.tolist()[0] + 1)\n",
    "            truth_list.append(1)\n",
    "        else:\n",
    "            truth_list.append(0)\n",
    "    else:\n",
    "        truth_list.append(2)\n",
    "\n",
    "cell_LR_data.y = torch.Tensor(truth_list).type(torch.LongTensor)\n",
    "\n",
    "truth_array = np.array(truth_list)\n",
    "positive_classes = np.where(truth_array==1)[0].tolist()\n",
    "negative_classes = np.where(truth_array==0)[0].tolist()[:len(positive_classes)]\n",
    "\n",
    "new_train_mask = np.array([False]*truth_array.shape[0])\n",
    "new_train_mask[positive_classes + negative_classes] = True\n",
    "\n",
    "model = GAT(cell_LR_data,num_classes=2).to(device)\n",
    "data = cell_LR_data.to(device)\n",
    "data.train_mask = torch.Tensor(new_train_mask).type(torch.LongTensor)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "ligands = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "receptors = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "truth_df = full_matrix.loc[cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist(),cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()]\n",
    "\n",
    "truth_Tensor = torch.Tensor(truth_df.values).to(device)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    #loss = F.nll_loss(out[new_train_mask],data.y[new_train_mask])\n",
    "    ligand_out = out[ligands,:]\n",
    "    receptor_out = out[receptors,:]\n",
    "    total_out = torch.inner(ligand_out,receptor_out)\n",
    "    #loss = criterion(out[LR_ids],data.y)\n",
    "    #loss = criterion(total_out,truth_Tensor)\n",
    "    loss = criterion(out[new_train_mask],data.y[new_train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "cell_LR_out = model(data)\n",
    "\n",
    "ligands = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "receptors = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "ligand_out = cell_LR_out[ligands,:]\n",
    "receptor_out = cell_LR_out[receptors,:]\n",
    "_,ligand_pred = ligand_out.max(dim=1)\n",
    "_,receptor_pred = receptor_out.max(dim=1)\n",
    "\n",
    "total_out = torch.inner(ligand_out,receptor_out).cpu().detach().numpy()\n",
    "ligand_pred = ligand_pred.cpu().detach().numpy()\n",
    "receptor_pred = receptor_pred.cpu().detach().numpy()\n",
    "\n",
    "cell_LR_nodes.index = cell_LR_nodes[\"Id\"].tolist()\n",
    "valid_ligand_df = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"]\n",
    "valid_ligand_df.index = range(valid_ligand_df.shape[0])\n",
    "valid_receptor_df = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"]\n",
    "valid_receptor_df.index = range(valid_receptor_df.shape[0])\n",
    "\n",
    "valid_ligands = valid_ligand_df.loc[np.where(ligand_pred == 1)]\n",
    "valid_receptors = valid_receptor_df.loc[np.where(receptor_pred == 1)]\n",
    "ligand_out = ligand_out[np.where(ligand_pred ==1)]\n",
    "receptor_out = receptor_out[np.where(receptor_pred ==1)]  \n",
    "total_out = torch.inner(ligand_out,receptor_out).cpu().detach().numpy()\n",
    "ligand_nodes = cell_LR_nodes[cell_LR_nodes[\"category\"] == \"Ligand\"]\n",
    "ligand_nodes.index = range(0,ligand_nodes.shape[0])\n",
    "ligand_idents = ligand_nodes.iloc[np.where(ligand_pred==1)]['identifier'].tolist()\n",
    "total_out_df = pd.DataFrame(total_out,index=valid_ligands[\"identifier\"].tolist(),columns=valid_receptors[\"identifier\"].tolist())\n",
    "indicies = np.where(total_out_df.values > 0)\n",
    "source = list(indicies[0])\n",
    "dest = list(indicies[1])\n",
    "index_df = pd.DataFrame({\"Id\":range(0,total_out_df.shape[0]),\"identifier\":total_out_df.index.tolist()})\n",
    "column_df = pd.DataFrame({\"Id\":range(0,total_out_df.shape[1]),\"identifier\":total_out_df.columns.tolist()})\n",
    "source_list = index_df.loc[source][\"identifier\"].tolist()\n",
    "dest_list = column_df.loc[dest][\"identifier\"].tolist()\n",
    "total_link_df = pd.DataFrame({\"Src\":source_list,\"Dst\":dest_list,\"Prob\":total_out_df.values[indicies]})\n",
    "total_link_df = total_link_df.sort_values(\"Prob\",ascending=False)\n",
    "Omnipath_db = pd.read_csv(\"../data/LR_database/Omnipath_database.csv\")\n",
    "total_link_df[\"Src\"] = [i.split(\"_\")[0] for i in total_link_df[\"Src\"].tolist()]\n",
    "total_link_df[\"Dst\"] = [i.split(\"_\")[0] for i in total_link_df[\"Dst\"].tolist()]\n",
    "total_link_df = total_link_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "    LR_out = cell_LR_out[valid_ligands[\"Id\"].tolist() + valid_receptors[\"Id\"].tolist(),:]\n",
    "    cell_group_out = cell_LR_out[cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Cell Group\"][\"Id\"].tolist(),:]\n",
    "    cell_LR_out = torch.inner(LR_out,cell_group_out).cpu().detach().numpy()\n",
    "\n",
    "    cell_LR_df = pd.DataFrame(cell_LR_out,index=valid_ligands[\"identifier\"].tolist() + valid_receptors[\"identifier\"].tolist(),columns=cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Cell Group\"][\"identifier\"].tolist())\n",
    "\n",
    "    ligands = nodes[nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "    receptors = nodes[nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()\n",
    "    expression_df = matrix\n",
    "\n",
    "    cell_groups = meta[\"labels\"].unique().tolist()\n",
    "\n",
    "\n",
    "    # In[30]:\n",
    "\n",
    "\n",
    "    mean_matrix = pd.DataFrame(columns=cell_groups,index=ligands+receptors)\n",
    "\n",
    "\n",
    "    # In[31]:\n",
    "\n",
    "\n",
    "    for i in cell_groups:\n",
    "        cells = meta[meta[\"labels\"]==i][\"cell\"].tolist()\n",
    "        temp_ligands = [i.split(\"_\")[0] for i in ligands]\n",
    "        ligand_df = expression_df[cells].mean(axis=1).loc[temp_ligands]\n",
    "        ligand_df.index = [i+\"_Ligand\" for i in ligand_df.index.tolist()]\n",
    "        temp_receptors = receptors = [i.split(\"_\")[0] for i in receptors]\n",
    "        receptor_df = expression_df[cells].mean(axis=1).loc[temp_receptors]\n",
    "        receptor_df.index = [i+\"_Receptor\" for i in receptor_df.index.tolist()]\n",
    "        total_df = pd.concat([ligand_df,receptor_df])\n",
    "        mean_matrix[i] = total_df.tolist()\n",
    "\n",
    "    ligands = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "    receptors = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "    interacting_ligands = list(set(ligands) & set(cell_LR_ints[\"Dst\"].tolist()))\n",
    "    interacting_receptors = list(set(receptors) & set(cell_LR_ints[\"Dst\"].tolist()))\n",
    "\n",
    "\n",
    "    # In[99]:\n",
    "\n",
    "\n",
    "    cell_LR_ints.index = cell_LR_ints[\"Dst\"].tolist()\n",
    "    ligand_cells = cell_LR_ints.loc[interacting_ligands][\"Src\"].unique().tolist()\n",
    "    receptor_cells = cell_LR_ints.loc[interacting_receptors][\"Src\"].unique().tolist()\n",
    "\n",
    "    cell_LR_out = torch.Tensor(cell_LR_out)\n",
    "\n",
    "    ligand_cell_out = out[ligand_cells,:]\n",
    "    ligand_out = out[ligands,:]\n",
    "    total_ligand_out = torch.inner(ligand_out,ligand_cell_out).cpu().detach().numpy()\n",
    "    receptor_cell_out = out[receptor_cells,:]\n",
    "    receptor_out = out[receptors,:]\n",
    "    total_receptor_out = torch.inner(receptor_out,receptor_cell_out).cpu().detach().numpy()\n",
    "\n",
    "    ligand_matrix = mean_matrix[mean_matrix.index.str.contains(\"Ligand\")]\n",
    "    receptor_matrix = mean_matrix[mean_matrix.index.str.contains(\"Receptor\")]\n",
    "\n",
    "\n",
    "    # In[112]:\n",
    "\n",
    "\n",
    "    ligand_cell_out = np.multiply(ligand_matrix,total_ligand_out)\n",
    "    receptor_cell_out = np.multiply(receptor_matrix,total_receptor_out)\n",
    "\n",
    "\n",
    "    # In[113]:\n",
    "\n",
    "\n",
    "    ligand_maxes = (ligand_cell_out.idxmax(axis=1))\n",
    "    receptor_maxes = (receptor_cell_out.idxmax(axis=1))\n",
    "\n",
    "\n",
    "    ligand_maxes.index = [i.split(\"_\")[0] for i in ligand_maxes.index.tolist()]\n",
    "    receptor_maxes.index = [i.split(\"_\")[0] for i in receptor_maxes.index.tolist()]\n",
    "\n",
    "    total_link_df[\"Src Cell\"] = ligand_maxes.loc[total_link_df['Src']].tolist()\n",
    "    total_link_df[\"Dst Cell\"] = receptor_maxes.loc[total_link_df['Dst']].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Dst</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Src Cell</th>\n",
       "      <th>Dst Cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13230108</th>\n",
       "      <td>ACAN</td>\n",
       "      <td>KCNJ5</td>\n",
       "      <td>1.727050</td>\n",
       "      <td>vSMCs</td>\n",
       "      <td>Myeloid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19216248</th>\n",
       "      <td>MED1</td>\n",
       "      <td>KCNJ5</td>\n",
       "      <td>1.726681</td>\n",
       "      <td>Myeloid</td>\n",
       "      <td>Myeloid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19150299</th>\n",
       "      <td>CLEC11A</td>\n",
       "      <td>KCNJ5</td>\n",
       "      <td>1.726379</td>\n",
       "      <td>vSMCs</td>\n",
       "      <td>Myeloid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15827484</th>\n",
       "      <td>UBASH3B</td>\n",
       "      <td>KCNJ5</td>\n",
       "      <td>1.726071</td>\n",
       "      <td>Myeloid</td>\n",
       "      <td>Myeloid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13226656</th>\n",
       "      <td>ACAN</td>\n",
       "      <td>GYS1</td>\n",
       "      <td>1.725974</td>\n",
       "      <td>vSMCs</td>\n",
       "      <td>Pericyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12748060</th>\n",
       "      <td>ALPL</td>\n",
       "      <td>PPP1R1B</td>\n",
       "      <td>1.685342</td>\n",
       "      <td>Endothelial</td>\n",
       "      <td>Fibroblast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8218906</th>\n",
       "      <td>SLAMF6</td>\n",
       "      <td>HOXB7</td>\n",
       "      <td>1.684533</td>\n",
       "      <td>Myeloid</td>\n",
       "      <td>Myeloid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12745564</th>\n",
       "      <td>ALPL</td>\n",
       "      <td>ENAM</td>\n",
       "      <td>1.683755</td>\n",
       "      <td>Endothelial</td>\n",
       "      <td>Cardiomyocyte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8222944</th>\n",
       "      <td>SLAMF6</td>\n",
       "      <td>PPP1R1B</td>\n",
       "      <td>1.682235</td>\n",
       "      <td>Myeloid</td>\n",
       "      <td>Fibroblast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8220448</th>\n",
       "      <td>SLAMF6</td>\n",
       "      <td>ENAM</td>\n",
       "      <td>1.680443</td>\n",
       "      <td>Myeloid</td>\n",
       "      <td>Cardiomyocyte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19652802 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Src      Dst      Prob     Src Cell       Dst Cell\n",
       "13230108     ACAN    KCNJ5  1.727050        vSMCs        Myeloid\n",
       "19216248     MED1    KCNJ5  1.726681      Myeloid        Myeloid\n",
       "19150299  CLEC11A    KCNJ5  1.726379        vSMCs        Myeloid\n",
       "15827484  UBASH3B    KCNJ5  1.726071      Myeloid        Myeloid\n",
       "13226656     ACAN     GYS1  1.725974        vSMCs       Pericyte\n",
       "...           ...      ...       ...          ...            ...\n",
       "12748060     ALPL  PPP1R1B  1.685342  Endothelial     Fibroblast\n",
       "8218906    SLAMF6    HOXB7  1.684533      Myeloid        Myeloid\n",
       "12745564     ALPL     ENAM  1.683755  Endothelial  Cardiomyocyte\n",
       "8222944    SLAMF6  PPP1R1B  1.682235      Myeloid     Fibroblast\n",
       "8220448    SLAMF6     ENAM  1.680443      Myeloid  Cardiomyocyte\n",
       "\n",
       "[19652802 rows x 5 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_link_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2. Node Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
