{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import liana as li\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "from openproblems import tasks\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F1op-CbyLuN4",
    "outputId": "77aaf048-dc7e-491d-a0ed-7a13f3692cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102\n",
      "1.12.0+cu102\n"
     ]
    }
   ],
   "source": [
    "# Install required packages.\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "# Helper function for visualization.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.datasets import Entities\n",
    "from torch_geometric.nn import FastRGCNConv, RGCNConv, GCNConv, InnerProductDecoder, GAE, VGAE\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data.data import Data\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.io import mmread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing from original matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#matrix = pd.read_csv(\"../data/GSE95025/GSM2494785_dge_mel_rep3.txt\",sep=\"\\t\")\n",
    "matrix_list = []\n",
    "common_genes = []\n",
    "for i,j in zip(range(3,8),range(5,10)):\n",
    "    matrix_list.append(pd.read_csv(f\"../data/GSE95025/GSM249478{j}_dge_mel_rep{i}.txt\",sep=\"\\t\",index_col=0))\n",
    "    if not common_genes:\n",
    "        common_genes = pd.read_csv(f\"../data/GSE95025/GSM249478{j}_dge_mel_rep{i}.txt\",sep=\"\\t\",index_col=0).index.tolist()\n",
    "    else:\n",
    "        common_genes = list(set(common_genes) & set(pd.read_csv(f\"../data/GSE95025/GSM249478{j}_dge_mel_rep{i}.txt\",sep=\"\\t\",index_col=0).index.tolist()))\n",
    "        #matrix_list = [i.loc[common_genes] for i in matrix_list]\n",
    "matrix = pd.concat(matrix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix.loc[common_genes]\n",
    "matrix = matrix[~matrix.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.index = [str(i).upper() for i in matrix.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import anndata\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = matrix.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.AnnData(matrix.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(adata, min_cells=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.leiden(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame({\"cell\":adata.obs[\"leiden\"].index.tolist(),\"labels\":adata.obs[\"leiden\"].tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.index = meta[\"cell\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix.loc[adata.var.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.tl.rank_genes_groups(adata, 'labels')\n",
    "cell_groups = meta['labels'].unique().tolist()\n",
    "matrix_list = {}\n",
    "for i in cell_groups:\n",
    "    cells = meta[meta[\"labels\"]==i].index.tolist()\n",
    "    temp_matrix = matrix[cells]\n",
    "    matrix_list[i] = (temp_matrix.mean(axis=1)[temp_matrix.mean(axis=1) > 0].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata.obs = meta\n",
    "# sc.tl.rank_genes_groups(adata, 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.tl.rank_genes_groups(adata, 'labels')\n",
    "\n",
    "\n",
    "# # In[12]:\n",
    "\n",
    "\n",
    "# pval_df = pd.DataFrame.from_records(adata.uns[\"rank_genes_groups\"][\"pvals\"])\n",
    "# pval_df.index = matrix.index.tolist()\n",
    "\n",
    "\n",
    "# # In[13]:\n",
    "\n",
    "\n",
    "# cell_type_df = {}\n",
    "# for i in pval_df.columns.tolist():\n",
    "#     sub = pval_df[i]\n",
    "#     sub = sub[sub < 0.05]\n",
    "#     cell_type_df[i] = sub.index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata = adata.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.obs[\"Gene\"] = matrix.index.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pval_df = pd.DataFrame.from_records(adata.uns[\"rank_genes_groups\"][\"pvals\"])\n",
    "# pval_df.index = adata.var.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_type_df = {}\n",
    "# for i in pval_df.columns.tolist():\n",
    "#     sub = pval_df[i]\n",
    "#     sub = sub[sub < 0.05]\n",
    "#     cell_type_df[i] = sub.index.tolist()\n",
    "cell_type_df = matrix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_expression = np.mean(matrix.values[matrix.values != 0])\n",
    "nodes = pd.DataFrame({\"category\":[],\"identifier\":[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes = pd.read_csv(\"../data/LR_database/OmniPath_nodes.csv\",index_col=0)\n",
    "Omnipath_network = pd.read_csv(\"../data/LR_database/OmniPath_interactions.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligands = LR_nodes[LR_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "receptors = LR_nodes[LR_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_list = []\n",
    "receptor_list = []\n",
    "new_cell_df = {}\n",
    "for i in cell_type_df.keys():\n",
    "    ligand_list.extend(list(set(ligands) & set(cell_type_df[i])))\n",
    "    receptor_list.extend(list(set(receptors) & set(cell_type_df[i])))\n",
    "    new_cell_df[i] = [list(set(ligands) & set(cell_type_df[i])),list(set(receptors) & set(cell_type_df[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_cell_df.keys():\n",
    "    new_cell_df[i][0] = [j+\"_Ligand\" for j in new_cell_df[i][0]]\n",
    "    new_cell_df[i][1] = [j+\"_Receptor\" for j in new_cell_df[i][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_list = list(set(ligand_list))\n",
    "receptor_list = list(set(receptor_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_list = [i+\"_Ligand\" for i in ligand_list]\n",
    "receptor_list = [i+\"_Receptor\" for i in receptor_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.concat([nodes,pd.DataFrame({\"category\":[\"Cell Group\"] * len(list(cell_type_df.keys())), \"identifier\":list(cell_type_df.keys())})])\n",
    "nodes = pd.concat([nodes,pd.DataFrame({\"category\":[\"Ligand\"] * len(ligand_list), \"identifier\":ligand_list})])\n",
    "nodes = pd.concat([nodes,pd.DataFrame({\"category\":[\"Receptor\"] * len(receptor_list), \"identifier\":receptor_list})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_identifier = [row[\"identifier\"] + \"_\" + row[\"category\"] for index,row in LR_nodes.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes[\"identifier\"] = new_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[\"Id\"] = range(0,nodes.shape[0])\n",
    "nodes = nodes[[\"Id\",\"category\",\"identifier\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.index = nodes.index.astype('int')\n",
    "nodes[\"Id\"] = nodes[\"Id\"].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.index = meta[\"cell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.DataFrame({\"Src\":[],\"Dst\":[],\"Weight\":[],\"edge_type\":[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes.index = LR_nodes[\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"identifier\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = []\n",
    "dest_list = []\n",
    "weight_list = []\n",
    "edge_type_list = []\n",
    "for i in new_cell_df.keys():\n",
    "    source_list.extend([i] * (len(new_cell_df[i][0]) + len(new_cell_df[i][1])))\n",
    "    dest_list.extend(new_cell_df[i][0])\n",
    "    dest_list.extend(new_cell_df[i][1])\n",
    "    weight_list.extend([1] * (len(new_cell_df[i][0]) + len(new_cell_df[i][1])))\n",
    "    edge_type_list.extend([1] * (len(new_cell_df[i][0]) + len(new_cell_df[i][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[\"Src\"] = source_list\n",
    "interactions[\"Dst\"] = dest_list\n",
    "interactions[\"Weight\"] = weight_list\n",
    "interactions[\"edge_type\"] = edge_type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.index = nodes[\"identifier\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nodes.drop_duplicates(\"identifier\")\n",
    "nodes[\"Id\"] = range(0,nodes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[\"Src\"] = nodes.loc[interactions[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "interactions[\"Dst\"] = nodes.loc[interactions[\"Dst\"].tolist()][\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data,first_nodes,first_interactions = make_dataset(nodes,interactions,first=False,pathway_encode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction with GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self,data,num_classes=3):\n",
    "        super(GAT, self).__init__()\n",
    "        self.hid = 3\n",
    "        self.in_head = 3\n",
    "        self.out_head = 3\n",
    "        \n",
    "        \n",
    "        self.conv1 = GATConv(data.x.shape[1], self.hid, heads=self.in_head, dropout=0.6)\n",
    "        self.conv2 = GATConv(self.hid*self.in_head,num_classes, concat=False,\n",
    "                             heads=self.out_head, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "                \n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.logsigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Omnipath embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes = pd.read_csv(\"../data/LR_database/OmniPath_nodes.csv\",index_col=0)\n",
    "Omnipath_network = pd.read_csv(\"../data/LR_database/OmniPath_interactions.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_identifier = [row[\"identifier\"] + \"_\" + row[\"category\"] for index,row in LR_nodes.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes[\"identifier\"] = new_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"identifier\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes = LR_nodes[(LR_nodes[\"identifier\"].isin(ligand_list)) | (LR_nodes[\"identifier\"].isin(receptor_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Omnipath_network = Omnipath_network[(Omnipath_network[\"Src\"].isin(LR_nodes[\"identifier\"].tolist())) & (Omnipath_network[\"Dst\"].isin(LR_nodes[\"identifier\"].tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes[\"Id\"] = range(0,LR_nodes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes.index = LR_nodes[\"identifier\"].tolist()\n",
    "Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes = LR_nodes[(LR_nodes[\"Id\"].isin(Omnipath_network[\"Src\"].tolist())) | (LR_nodes[\"Id\"].isin(Omnipath_network[\"Dst\"].tolist()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes.index = LR_nodes[\"Id\"].tolist()\n",
    "Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"identifier\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_nodes.index = LR_nodes[\"identifier\"].tolist()\n",
    "LR_nodes[\"Id\"] = range(0,LR_nodes.shape[0])\n",
    "Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Node2Vec\n",
    "import os.path as osp\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,loader,optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in (loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    z = model()\n",
    "    acc = model.test(z[data.train_mask], data.y[data.train_mask],\n",
    "                     z[data.test_mask], data.y[data.test_mask],\n",
    "                     max_iter=150)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Omnipath_embeddings(nodes,interactions):\n",
    "    Omnipath_data,Omnipath_nodes,Omnipath_interactions = make_dataset(nodes,interactions,first=False,pathway_encode=False)\n",
    "    node_info = pd.DataFrame(np.zeros((Omnipath_nodes.shape[0],Omnipath_nodes.shape[0])),index=Omnipath_nodes[\"identifier\"].tolist(),columns=Omnipath_nodes[\"identifier\"].tolist())\n",
    "\n",
    "    temp_identifiers = [i.split(\"_\")[0] for i in Omnipath_nodes[\"identifier\"].tolist()]\n",
    "\n",
    "    complexes = pd.read_csv(\"../data/data/LR_database/complexes.csv\")\n",
    "    complexes = complexes[complexes[\"member\"].isin(temp_identifiers)]\n",
    "\n",
    "    temp_nodes = Omnipath_nodes.copy()\n",
    "    temp_nodes.index = temp_identifiers\n",
    "    temp_nodes = temp_nodes[~temp_nodes.index.duplicated(keep='first')]\n",
    "\n",
    "    complexes[\"member\"] = temp_nodes.loc[complexes[\"member\"].tolist()][\"identifier\"].tolist()\n",
    "\n",
    "    group_complex = complexes.groupby(\"complex\").agg(list)\n",
    "\n",
    "    group_complex.index=range(0,group_complex.shape[0])\n",
    "\n",
    "    for index,row in group_complex.iterrows():\n",
    "        node_info.loc[list(set(row[\"member\"])),list(set(row[\"member\"]))] = index\n",
    "\n",
    "    # for i in group_complex[\"member\"].tolist():\n",
    "    #     node_info.loc[list(set(i)),list(set(i))] = 1\n",
    "\n",
    "    pathways = pd.read_csv(\"../data/kegg_pathways.csv\",index_col=0)\n",
    "    pathways = pathways[pathways[\"genesymbol\"].isin(temp_identifiers)]\n",
    "    pathways[\"genesymbol\"] = temp_nodes.loc[pathways[\"genesymbol\"].tolist()][\"identifier\"].tolist()\n",
    "    group_pathway = pathways.groupby(\"pathway\").agg(list)\n",
    "\n",
    "    group_pathway.index=range(0,group_pathway.shape[0])\n",
    "\n",
    "    for index,row in group_pathway.iterrows():\n",
    "        node_info.loc[list(set(row[\"genesymbol\"])),list(set(row[\"genesymbol\"]))] += index\n",
    "\n",
    "    # for i in group_pathway[\"genesymbol\"].tolist():\n",
    "    #     node_info.loc[list(set(i)),list(set(i))] += 1\n",
    "\n",
    "    truth_info = pd.DataFrame(np.zeros((Omnipath_nodes.shape[0],Omnipath_nodes.shape[0])),index=Omnipath_nodes[\"identifier\"].tolist(),columns=Omnipath_nodes[\"identifier\"].tolist())\n",
    "\n",
    "    Omnipath_nodes.index = Omnipath_nodes[\"Id\"].tolist()\n",
    "\n",
    "    ident_interactions = Omnipath_interactions.copy()\n",
    "    ident_interactions[\"Src\"] = Omnipath_nodes.loc[ident_interactions[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "    ident_interactions[\"Dst\"] = Omnipath_nodes.loc[ident_interactions[\"Dst\"].tolist()][\"identifier\"].tolist()\n",
    "\n",
    "    for index,row in ident_interactions.iterrows():\n",
    "        truth_info.loc[row[\"Src\"],row[\"Dst\"]] = 1\n",
    "\n",
    "    ligands = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "    receptors = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()\n",
    "    #truth_info = truth_info.loc[ligands,receptors]\n",
    "    truth_info = torch.Tensor(truth_info.values).to(device)\n",
    "\n",
    "\n",
    "    ligands = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "    receptors = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "\n",
    "    ident_interactions = ident_interactions.drop_duplicates(\"Src\")\n",
    "    ident_interactions = ident_interactions.drop_duplicates(\"Dst\")\n",
    "\n",
    "    ident_interactions.index = range(0,ident_interactions.shape[0])\n",
    "\n",
    "    truth_list = []\n",
    "    for i in Omnipath_nodes[\"identifier\"].tolist():\n",
    "        if \"Ligand\" in i:\n",
    "            if i in ident_interactions[\"Src\"].tolist():\n",
    "                #truth_list.append(ident_interactions[ident_interactions[\"Src\"]==i].index.tolist()[0] + 1)\n",
    "                truth_list.append(1)\n",
    "            else:\n",
    "                truth_list.append(0)\n",
    "        if \"Receptor\" in i:\n",
    "            if i in ident_interactions[\"Dst\"].tolist():\n",
    "                #truth_list.append(ident_interactions[ident_interactions[\"Dst\"]==i].index.tolist()[0] + 1)\n",
    "                truth_list.append(1)\n",
    "            else:\n",
    "                truth_list.append(0)\n",
    "\n",
    "    node_info.values[np.where(np.isnan(node_info.values))] = 0\n",
    "    node_info.values[np.where(np.isinf(node_info.values))] = 0\n",
    "\n",
    "    Omnipath_data.x = torch.Tensor(node_info.values)\n",
    "\n",
    "    Omnipath_data.y = torch.Tensor(truth_list).type(torch.LongTensor)\n",
    "    #Omnipath_data.y = truth_info\n",
    "\n",
    "    Omnipath_nodes.index = Omnipath_nodes[\"Id\"].tolist()\n",
    "\n",
    "    Omnipath_interactions[\"Src\"] = [Omnipath_nodes.loc[i][\"identifier\"] for i in Omnipath_interactions[\"Src\"].tolist()]\n",
    "    Omnipath_interactions[\"Dst\"] = [Omnipath_nodes.loc[i][\"identifier\"] for i in Omnipath_interactions[\"Dst\"].tolist()]\n",
    "\n",
    "    #edge_weights = [max(node_info.loc[i,j],node_info.loc[j,i]) for i,j in zip(Omnipath_interactions[\"Src\"].tolist(),Omnipath_interactions[\"Dst\"].tolist())]\n",
    "    edge_weights = [1 for i,j in zip(Omnipath_interactions[\"Src\"].tolist(),Omnipath_interactions[\"Dst\"].tolist())]\n",
    "    data = Omnipath_data\n",
    "    model = Node2Vec(data.edge_index, embedding_dim=2, walk_length=40,\n",
    "         context_size=40, walks_per_node=10,\n",
    "         num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
    "\n",
    "    loader = model.loader(batch_size=2, shuffle=True, num_workers=4)\n",
    "    optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
    "    \n",
    "    \n",
    "    for epoch in range(1, 100):\n",
    "        loss = train(model,loader,optimizer)\n",
    "        #acc = test()\n",
    "#         if epoch % 10 == 0:\n",
    "#             print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
    "    model.eval()\n",
    "    z = model(torch.arange(data.num_nodes)).detach()\n",
    "\n",
    "    ligand_ids = Omnipath_nodes[Omnipath_nodes[\"category\"].str.contains(\"Ligand\")][\"Id\"].tolist()\n",
    "    receptor_ids = Omnipath_nodes[Omnipath_nodes[\"category\"].str.contains(\"Receptor\")][\"Id\"].tolist()\n",
    "\n",
    "    ligand_embeddings = z[ligand_ids,:]\n",
    "    receptor_embeddings = z[receptor_ids,:]\n",
    "\n",
    "    total_embeddings = torch.inner(ligand_embeddings,receptor_embeddings)\n",
    "\n",
    "    total_embeddings_df = pd.DataFrame(total_embeddings.numpy(),index=Omnipath_nodes[Omnipath_nodes[\"category\"].str.contains(\"Ligand\")][\"identifier\"].tolist(),columns=Omnipath_nodes[Omnipath_nodes[\"category\"].str.contains(\"Receptor\")][\"identifier\"].tolist())\n",
    "    return total_embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if (Omnipath_network[\"Src\"].dtype != 'float64') and (Omnipath_network[\"Src\"].dtype != 'int64'):\n",
    "        LR_nodes.index = LR_nodes[\"identifier\"].tolist()\n",
    "        LR_nodes[\"Id\"] = range(0,LR_nodes.shape[0])\n",
    "        Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "        Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"Id\"].tolist()\n",
    "Omnipath_data,Omnipath_nodes,Omnipath_interactions = make_dataset(LR_nodes,Omnipath_network,first=False,pathway_encode=False)\n",
    "Omnipath_nodes.index = Omnipath_nodes[\"Id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "def get_cell_LR_embeddings(nodes,interactions,total_embeddings_df,Omnipath_nodes):\n",
    "    device = 'cpu'\n",
    "    truth_info = pd.DataFrame(np.zeros((Omnipath_nodes.shape[0],Omnipath_nodes.shape[0])),index=Omnipath_nodes[\"identifier\"].tolist(),columns=Omnipath_nodes[\"identifier\"].tolist())\n",
    "\n",
    "    #Omnipath_nodes.index = Omnipath_nodes[\"Id\"].tolist()\n",
    "\n",
    "    ident_interactions = Omnipath_interactions.copy()\n",
    "    ident_interactions[\"Src\"] = Omnipath_nodes.loc[ident_interactions[\"Src\"].tolist()][\"identifier\"].tolist()\n",
    "    ident_interactions[\"Dst\"] = Omnipath_nodes.loc[ident_interactions[\"Dst\"].tolist()][\"identifier\"].tolist()\n",
    "\n",
    "    for index,row in ident_interactions.iterrows():\n",
    "        truth_info.loc[row[\"Src\"],row[\"Dst\"]] = 1\n",
    "\n",
    "    ligands = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "    receptors = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()\n",
    "    #truth_info = truth_info.loc[ligands,receptors]\n",
    "    truth_info = torch.Tensor(truth_info.values).to(device)\n",
    "\n",
    "    \n",
    "    cell_LR_data,cell_LR_nodes,cell_LR_ints = make_dataset(nodes,interactions,first=False,pathway_encode=False)\n",
    "\n",
    "    full_matrix = pd.DataFrame(np.zeros((cell_LR_nodes.shape[0],cell_LR_nodes.shape[0])),index=cell_LR_nodes[\"identifier\"].tolist(),columns=cell_LR_nodes[\"identifier\"].tolist())\n",
    "\n",
    "    ligands = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "    receptors = Omnipath_nodes[Omnipath_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "    total_out_df = total_embeddings_df\n",
    "\n",
    "    gene_mean = matrix.mean(axis=1)\n",
    "\n",
    "    Omnipath_nodes.index = [i.split(\"_\")[0] for i in Omnipath_nodes[\"identifier\"].tolist()]\n",
    "\n",
    "    Omnipath_nodes = Omnipath_nodes.loc[~Omnipath_nodes.index.duplicated(),:].copy()\n",
    "    \n",
    "\n",
    "    gene_mean = gene_mean.loc[Omnipath_nodes.index.tolist()]\n",
    "\n",
    "    gene_mean.index = Omnipath_nodes[\"identifier\"].tolist()\n",
    "\n",
    "    ligands = [i for i in gene_mean.index.tolist() if \"Ligand\" in i]\n",
    "    receptors = [i for i in gene_mean.index.tolist() if \"Receptor\" in i]\n",
    "    ligands = list(set(full_matrix.index.tolist()) & set(ligands))\n",
    "    receptors = list(set(full_matrix.index.tolist()) & set(receptors))\n",
    "\n",
    "    for i,j in zip(ligands,receptors):\n",
    "        if (i in gene_mean.index.tolist()) and (j in gene_mean.index.tolist()):\n",
    "            full_matrix.loc[i,j] = gene_mean.loc[i]*gene_mean.loc[j]\n",
    "\n",
    "    ligands = list(set(ligands) & set(total_out_df.index.tolist()))\n",
    "    receptors = list(set(receptors) & set(total_out_df.columns.tolist()))\n",
    "\n",
    "    for i,j in zip(ligands,receptors):\n",
    "        full_matrix.loc[i,j] += total_out_df.loc[i,j]\n",
    "\n",
    "\n",
    "    #full_matrix.loc[true_df.index.tolist(),true_df.columns.tolist()] = true_df.values\n",
    "\n",
    "    cell_groups = meta[\"labels\"].unique().tolist()\n",
    "\n",
    "    ligands = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist()\n",
    "    ligands = [i.split(\"_\")[0] for i in ligands]\n",
    "    ligand_matrix = matrix.loc[ligands]\n",
    "\n",
    "    ligand_matrix = ligand_matrix[~ligand_matrix.index.duplicated(keep='first')]\n",
    "\n",
    "\n",
    "    mean_dict = {}\n",
    "    for i in cell_groups:\n",
    "        cells = meta[meta[\"labels\"]==i][\"cell\"].tolist()\n",
    "        mean_dict[i] = ligand_matrix[cells].mean(axis=1)\n",
    "\n",
    "    full_matrix = full_matrix[~full_matrix.index.duplicated(keep='first')]\n",
    "    full_matrix = full_matrix.loc[:,~full_matrix.columns.duplicated()].copy()\n",
    "\n",
    "\n",
    "    for i in mean_dict.keys():\n",
    "        temp_index = [i+\"_Ligand\" for i in mean_dict[i].index.tolist()]\n",
    "        full_matrix.loc[i,temp_index] = mean_dict[i].values\n",
    "        full_matrix.loc[temp_index,i] = mean_dict[i].values\n",
    "\n",
    "    receptors = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()\n",
    "    receptors = [i.split(\"_\")[0] for i in receptors]\n",
    "    receptors_matrix = matrix.loc[receptors]\n",
    "\n",
    "    receptors_matrix = receptors_matrix[~receptors_matrix.index.duplicated(keep='first')]\n",
    "\n",
    "\n",
    "    mean_dict = {}\n",
    "    for i in cell_groups:\n",
    "        cells = meta[meta[\"labels\"]==i][\"cell\"].tolist()\n",
    "        mean_dict[i] = receptors_matrix[cells].mean(axis=1)\n",
    "\n",
    "    full_matrix = full_matrix[~full_matrix.index.duplicated(keep='first')]\n",
    "    full_matrix = full_matrix.loc[:,~full_matrix.columns.duplicated()].copy()\n",
    "\n",
    "\n",
    "    for i in mean_dict.keys():\n",
    "        temp_index = [i+\"_Receptor\" for i in mean_dict[i].index.tolist()]\n",
    "        full_matrix.loc[i,temp_index] = mean_dict[i].values\n",
    "        full_matrix.loc[temp_index,i] = mean_dict[i].values\n",
    "\n",
    "    #full_matrix = (full_matrix - np.min(full_matrix)) / (np.max(full_matrix) - np.min(full_matrix))\n",
    "\n",
    "    full_matrix.values[np.where(np.isnan(full_matrix.values))] = 0\n",
    "    full_matrix.values[np.where(np.isinf(full_matrix.values))] = 0\n",
    "\n",
    "    cell_LR_data.x = torch.Tensor(full_matrix.values)\n",
    "\n",
    "    LR_ids = cell_LR_nodes[(cell_LR_nodes[\"category\"]==\"Ligand\") | (cell_LR_nodes[\"category\"]==\"Receptor\")][\"Id\"].tolist()\n",
    "\n",
    "    # true_values[\"Src\"] = [i + \"_Ligand\" for i in true_values[\"Src\"].tolist()]\n",
    "    # true_values[\"Dst\"] = [i + \"_Receptor\" for i in true_values[\"Dst\"].tolist()]\n",
    "\n",
    "    cell_groups = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Cell Group\"]['identifier'].tolist()\n",
    "\n",
    "    truth_list = []\n",
    "    for i in cell_LR_nodes[\"identifier\"].tolist():\n",
    "        if \"Ligand\" in i:\n",
    "            if i in ident_interactions[\"Src\"].tolist():\n",
    "                #truth_list.append(ident_interactions[ident_interactions[\"Src\"]==i].index.tolist()[0] + 1)\n",
    "                truth_list.append(1)\n",
    "            else:\n",
    "                truth_list.append(0)\n",
    "        elif \"Receptor\" in i:\n",
    "            if i in ident_interactions[\"Dst\"].tolist():\n",
    "                #truth_list.append(ident_interactions[ident_interactions[\"Dst\"]==i].index.tolist()[0] + 1)\n",
    "                truth_list.append(1)\n",
    "            else:\n",
    "                truth_list.append(0)\n",
    "        else:\n",
    "            truth_list.append(2)\n",
    "\n",
    "    cell_LR_data.y = torch.Tensor(truth_list).type(torch.LongTensor)\n",
    "\n",
    "    truth_array = np.array(truth_list)\n",
    "    positive_classes = np.where(truth_array==1)[0].tolist()\n",
    "    negative_classes = np.where(truth_array==0)[0].tolist()[:len(positive_classes)]\n",
    "\n",
    "    new_train_mask = np.array([False]*truth_array.shape[0])\n",
    "    new_train_mask[positive_classes + negative_classes] = True\n",
    "\n",
    "    model = GAT(cell_LR_data,num_classes=2).to(device)\n",
    "    data = cell_LR_data.to(device)\n",
    "    data.train_mask = torch.Tensor(new_train_mask).type(torch.LongTensor)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    ligands = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "    receptors = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "    truth_df = full_matrix.loc[cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"identifier\"].tolist(),cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"identifier\"].tolist()]\n",
    "\n",
    "    truth_Tensor = torch.Tensor(truth_df.values).to(device)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        #loss = F.nll_loss(out[new_train_mask],data.y[new_train_mask])\n",
    "        ligand_out = out[ligands,:]\n",
    "        receptor_out = out[receptors,:]\n",
    "        total_out = torch.inner(ligand_out,receptor_out)\n",
    "        #loss = criterion(out[LR_ids],data.y)\n",
    "        #loss = criterion(total_out,truth_Tensor)\n",
    "        loss = criterion(out[new_train_mask],data.y[new_train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    cell_LR_out = model(data)\n",
    "\n",
    "    ligands = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Ligand\"][\"Id\"].tolist()\n",
    "    receptors = cell_LR_nodes[cell_LR_nodes[\"category\"]==\"Receptor\"][\"Id\"].tolist()\n",
    "\n",
    "    ligand_out = cell_LR_out[ligands,:]\n",
    "    receptor_out = cell_LR_out[receptors,:]\n",
    "    _,ligand_pred = ligand_out.max(dim=1)\n",
    "    _,receptor_pred = receptor_out.max(dim=1)\n",
    "\n",
    "    total_out = torch.inner(ligand_out,receptor_out).cpu().detach().numpy()\n",
    "    ligand_pred = ligand_pred.cpu().detach().numpy()\n",
    "    receptor_pred = receptor_pred.cpu().detach().numpy()\n",
    "    \n",
    "    cell_LR_nodes.index = cell_LR_nodes[\"Id\"].tolist()\n",
    "    valid_ligands = cell_LR_nodes.loc[np.where(ligand_pred == 1)]\n",
    "    valid_receptors = cell_LR_nodes.loc[np.where(receptor_pred == 1)]\n",
    "    ligand_out = ligand_out[np.where(ligand_pred ==1)]\n",
    "    receptor_out = receptor_out[np.where(receptor_pred ==1)]  \n",
    "    total_out = torch.inner(ligand_out,receptor_out).cpu().detach().numpy()\n",
    "    ligand_nodes = cell_LR_nodes[cell_LR_nodes[\"category\"] == \"Ligand\"]\n",
    "    ligand_nodes.index = range(0,ligand_nodes.shape[0])\n",
    "    ligand_idents = ligand_nodes.iloc[np.where(ligand_pred==1)]['identifier'].tolist()\n",
    "    total_out_df = pd.DataFrame(total_out,index=valid_ligands[\"identifier\"].tolist(),columns=valid_receptors[\"identifier\"].tolist())\n",
    "    indicies = np.where(total_out_df.values > 0)\n",
    "    source = list(indicies[0])\n",
    "    dest = list(indicies[1])\n",
    "    index_df = pd.DataFrame({\"Id\":range(0,total_out_df.shape[0]),\"identifier\":total_out_df.index.tolist()})\n",
    "    column_df = pd.DataFrame({\"Id\":range(0,total_out_df.shape[1]),\"identifier\":total_out_df.columns.tolist()})\n",
    "    source_list = index_df.loc[source][\"identifier\"].tolist()\n",
    "    dest_list = column_df.loc[dest][\"identifier\"].tolist()\n",
    "    total_link_df = pd.DataFrame({\"Src\":source_list,\"Dst\":dest_list,\"Prob\":total_out_df.values[indicies]})\n",
    "    total_link_df = total_link_df.sort_values(\"Prob\",ascending=False)\n",
    "    Omnipath_db = pd.read_csv(\"../data/LR_database/Omnipath_database.csv\")\n",
    "    total_link_df[\"Src\"] = [i.split(\"_\")[0] for i in total_link_df[\"Src\"].tolist()]\n",
    "    total_link_df[\"Dst\"] = [i.split(\"_\")[0] for i in total_link_df[\"Dst\"].tolist()]\n",
    "    total_link_df = total_link_df.drop_duplicates()\n",
    "    return total_link_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for i in range(1000):\n",
    "    print(i)\n",
    "    Omnipath_network[\"Src\"] = Omnipath_network[\"Src\"].sample(frac=1).tolist()\n",
    "    Omnipath_network[\"Dst\"] = Omnipath_network[\"Dst\"].sample(frac=1).tolist()\n",
    "    if (Omnipath_network[\"Src\"].dtype != 'float64') and (Omnipath_network[\"Src\"].dtype != 'int64'):\n",
    "        LR_nodes.index = LR_nodes[\"identifier\"].tolist()\n",
    "        LR_nodes[\"Id\"] = range(0,LR_nodes.shape[0])\n",
    "        Omnipath_network[\"Src\"] = LR_nodes.loc[Omnipath_network[\"Src\"].tolist()][\"Id\"].tolist()\n",
    "        Omnipath_network[\"Dst\"] = LR_nodes.loc[Omnipath_network[\"Dst\"].tolist()][\"Id\"].tolist()\n",
    "    df = get_Omnipath_embeddings(LR_nodes,Omnipath_network)\n",
    "    interactions[\"Src\"] = interactions[\"Src\"].sample(frac=1).tolist()\n",
    "    interactions[\"Dst\"] = interactions[\"Dst\"].sample(frac=1).tolist()  \n",
    "    Omnipath_nodes.index = Omnipath_nodes[\"identifier\"].tolist()\n",
    "    df_list.append(get_cell_LR_embeddings(nodes,interactions,df,Omnipath_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_list)):\n",
    "    df_list[i].to_csv(f\"../results/GSE95025/Drosophila_{i+1}_random.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2. Node Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
